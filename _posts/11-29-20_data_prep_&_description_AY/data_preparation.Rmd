---
title: "Data preparation and description"
description: |
 Now we got our datasets, let's see how to prepare (join) them for analysis.
author:
  - name: Asha
    url:
    affiliation: University of Oregon
    affiliation_url:
date: 11-28-2020
output:
  distill::distill_article:
    self_contained: false
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(tidyverse)
library(tidymodels)
library(baguette)
library(future)
library(here)
library(rio)
library(corrplot)
library(skimr)

```
## 1. Packages 

For the purpose of data loading and cleaning, we are using following packages in R:
`{tidyverse}`,
`{here}`,
`{rio}`, and
`{skimr}`

## 2. Joining the datasets

For the purpose of demonstration, we will be using 1% of the data with `sample_frac()` to keep computing time low. All our datasets have `school ids` which we used as `key` to join the datasets.

After loading our five datasets, we joined them together to make one cohesive dataset, to be used for ML modeling. After joining, the dataset contains student-level variables (e.g. gender, ethnicity, enrollement in special education, etc.) as well as district-level variables ( school longitude and latitude, proportion of free and reduced lunch, etc.). All of these variables will be used in our ML models to predict student score in the statewide assessment. Here is the preview of our final dataset, ready to be used for ML modeling.

```{r}
set.seed(3000)


git <- "~/Documents/GitHub/EDLD-654-Final"

data <- import(here("data", "train.csv")) %>%
  select(-classification) %>%
  mutate_if(is.character, factor) %>%
  mutate(ncessch = as.double(ncessch)) 

bonus <- import(here("data", "bonus_data.csv")) %>%
  mutate(pupil_tch_ratio = as.numeric(pupil_tch_ratio)) %>%
  mutate(ncessch = as.double(ncessch))

## join data
data <- data %>% 
  left_join(bonus)

```


```{r}

#skim(data)

```





