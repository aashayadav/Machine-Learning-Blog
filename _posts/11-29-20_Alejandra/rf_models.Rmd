---
title: "Random Forest"
description: |
    This is how fitting a Random Forest went for me! 
author:
  - name: Alejandra
    url:
    affiliation: University of Oregon
    affiliation_url:
date: 11-28-2020
output:
  distill::distill_article:
    self_contained: false
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(rio)
library(here)
library(tidyverse)
library(tidymodels)

options(scipen=999)
```

Sample a fraction, but use HPC to run model with 50% of the data.
```{r}
set.seed(3000)

full_train <- import(here("data", "train.csv"), setclass = "tbl_df") %>%
  select(-classification) %>%
  mutate_if(is.character, factor) %>%
  mutate(ncessch = as.double(ncessch)) %>%
  sample_frac(0.05)

bonus <- import(here("data", "bonus_data.csv")) %>%
  mutate(pupil_tch_ratio = as.numeric(pupil_tch_ratio)) %>%
  mutate(ncessch = as.double(ncessch))

## joining data
data <- left_join(full_train, bonus)
```
Split & resample
```{r}
set.seed(3000)
data_split <- initial_split(data)

set.seed(3000)
data_train <- training(data_split)
data_test <- testing(data_split)

set.seed(3000)
cv <- vfold_cv(data_train)
```

Preprocess
```{r}
rec <- recipe(score ~ ., data_train) %>%
  step_mutate(tst_dt = lubridate::mdy_hms(tst_dt),
              lang_cd = case_when(lang_cd == "S" ~ "S", TRUE ~ "E"),
              pupil_tch_ratio = as.numeric(pupil_tch_ratio)) %>% 
  update_role(contains("id"), ncessch, ncesag, sch_name, new_role = "id_vars") %>%
  step_zv(all_predictors(), -starts_with("lang_cd")) %>%
  step_medianimpute(all_numeric(), -all_outcomes(), -has_role("id_vars")) %>%
  step_novel(all_nominal()) %>%
  step_unknown(all_nominal()) %>% 
  step_dummy(all_nominal()) %>%
  step_nzv(all_predictors(), -starts_with("lang_cd"))
```

```{r}
sum(rec$var_info$role == "predictor") # 77 predictors

(cores <- parallel:: detectCores())

rf_def <- rand_forest() %>% 
  set_engine("ranger",
             num.threads = cores,
             importance = "permutation",
             verbose = TRUE) %>% 
  set_mode("regression")  

# translate(rf_def) 

### workflow for default model
rf_def_wkflw <- workflow() %>% 
  add_model(rf_def) %>% 
  add_recipe(rec)
```


"Start with five evenly spaced values of mtry across the range 2– p centered at the recommended default"
77/3 # aprox. 26

"When adjusting node size start with three values between 1–10 and adjust depending on impact to accuracy and run time."

"A good rule of thumb is to start with 10 times the number of features" 
77*10 # 770. We'll go for 1000 trees. 


```{r, eval=FALSE}

mtry_search <- seq(2, 50, 12) # using the suggestion in book
min_n_search <- seq(1, 10, 3) # using the suggestion in book

grd <- expand.grid(mtry_search, min_n_search)

hyp_rf_search <- function(mtry_val, min_n_val, wf) {
  mod <- rand_forest() %>% 
    set_engine("ranger",
               num.threads = cores,
               importance = "permutation",
               verbose = TRUE) %>% 
    set_mode("regression") %>% 
    set_args(mtry = {{mtry_val}},
             min_n = {{min_n_val}},
             trees = 1000)
  
  wf <- wf %>% # shouldn't I be using rf_def_wkflw here??
    update_model(mod)
  
  rmse <- fit(wf, data_train) %>% 
    extract_rmse()
  
  tibble(mtry = mtry_val, min_n = min_n_val, rmse = rmse, workflow = list(wf))
}

tictoc::tic()
mtry_results_1 <- map2_df(grd$Var1, grd$Var2, ~hyp_rf_search(.x, .y, rf_def_wkflw))
tictoc::toc()
```
```{r, include=FALSE}
saveRDS(mtry_results_1, "mtry_results_1.Rds")
```


These are my results

```{r, echo=FALSE}

mtry_results_1 %>%
  arrange(rmse) # Best mtry = 10 & min_n = 14 or 26 for an rmse of 93.6

### plot 1###
mtry_results_1 %>%
  ggplot(aes(mtry, rmse)) +
  geom_line() +
  geom_point() +
  facet_wrap(~min_n)
```

